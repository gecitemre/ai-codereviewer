{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oGuKQ2z3w4TI",
        "IDD9sTc9yXTq",
        "R9rNpdLj53nn"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gecitemre/ai-codereviewer/blob/main/CENG403_2025_Spring_THE2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Take-Home Exam 2 (THE-2)**\n",
        "## CENG403 - Spring 2025\n",
        "\n",
        "In this THE, we will focus on implementing a CNN and an RNN from scratch or using PyTorch:\n",
        "\n",
        "*   Task 1: Implementing a forward function of your own deformable CNN from scratch (30 pts).\n",
        "*   Task 2: Implementing CNN in PyTorch (40 pts).\n",
        "*   Task 3: Implementing RNN using torch.autograd (30 pts).\n",
        "\n",
        "**Getting Ready**\n",
        "\n",
        "You can use the following tutorials if you need more details about the libraries/tools you will use:\n",
        "\n",
        "*   **Jupyter Notebook and Colab**:\n",
        " * https://www.dataquest.io/blog/jupyter-notebook-tutorial/\n",
        " * https://colab.research.google.com/\n",
        "* **NumPy**\n",
        " * https://numpy.org/devdocs/user/quickstart.html\n",
        "* **PyTorch**:\n",
        " * https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n"
      ],
      "metadata": {
        "id": "iB0of46BAKM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 1: Implement a Forward Pass of Your Own Deformable CNN (30 Points)**\n",
        "\n",
        "In this task, you are responsible for implementing the forward pass of [deformable convolution v2](https://arxiv.org/abs/1811.11168).\n",
        "\n",
        "**Note that you should implement all functions from scratch! Using PyTorch or any other libraries except for `numpy` in your implementation will be evaluated as 0 (zero).**\n"
      ],
      "metadata": {
        "id": "aeX1wLM2AO1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Forward Pass Implementation (30 Points)**\n",
        "\n",
        "Standard convolution (along one dimension of the input layer) with a filter size of $K$ at location $\\mathbf{p}_0$ can be formally defined as:\n",
        "\n",
        "$$\n",
        "\\mathbf{a}^{l+1}(\\mathbf{p}_0) = \\sum_{k=0}^{K-1}  \\mathbf{w}(k) \\cdot \\mathbf{a}^l(\\mathbf{p}_0 + \\mathbf{p}_k),\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "*    $\\mathbf{a}^l$ is the input feature map,\n",
        "*    $\\mathbf{a}^{l+1}$ is the output feature map,\n",
        "*    $\\mathbf{w}$ is the convolution kernel,\n",
        "*    $\\mathbf{p}_k$ is the fixed offset of the $k$-th sampling location (e.g., for a 1D feature map and a filter size of 3, $\\mathbf{p}_k \\in \\{0, 1, 2\\}$).\n",
        "\n",
        "\n",
        "Deformable convolution v2 introduces learnable offsets $\\Delta \\mathbf{p}_k$ and modulation scalars $m_k \\in [0,1]$:\n",
        "\n",
        "$$\n",
        "\\mathbf{a}^{l+1}(\\mathbf{p}_0) = \\sum_{k=0}^{K-1} \\mathbf{w}(k) \\cdot \\left( m_k \\cdot \\mathbf{a}^l(\\mathbf{p}_0 + \\mathbf{p}_k + \\Delta \\mathbf{p}_k) \\right),\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "*    $\\Delta \\mathbf{p}_k$ are learned dynamic offsets,\n",
        "*    $m_k$ are learned modulation scalars (also called a mask).\n",
        "\n",
        "Since $\\mathbf{p}_0 + \\mathbf{p}_k + \\Delta \\mathbf{p}_k$ may be fractional, bilinear interpolation is used. For any fractional position $\\mathbf{q}$ with $x$ and $y$ coordinates  $\\mathbf{q} = (q_x, q_y)$, we first identify the closest integer positions:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{p}_{\\text{lt}} &= (\\lfloor q_x \\rfloor, \\lfloor q_y \\rfloor) \\quad \\text{(left top)}, \\\\\n",
        "\\mathbf{p}_{\\text{rt}} &= (\\lceil q_x \\rceil, \\lfloor q_y \\rfloor) \\quad \\text{(right top)}, \\\\\n",
        "\\mathbf{p}_{\\text{lb}} &= (\\lfloor q_x \\rfloor, \\lceil q_y \\rceil) \\quad \\text{(left bottom)}, \\\\\n",
        "\\mathbf{p}_{\\text{rb}} &= (\\lceil q_x \\rceil, \\lceil q_y \\rceil) \\quad \\text{(right bottom)},\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $\\lfloor \\cdot \\rfloor$ denotes rounding down, and $\\lceil \\cdot \\rceil$ rounding up to the closest integer.\n",
        "\n",
        "Given these closest integer positions, bilinear interpolation for a fractional position $\\mathbf{q}$ can be defined as:\n",
        "\n",
        "$$\n",
        "\\mathbf{a}(\\mathbf{q}) = \\sum_{\\mathbf{p}_i \\in \\{\\mathbf{p}_{\\text{lt}}, \\mathbf{p}_{\\text{rt}}, \\mathbf{p}_{\\text{lb}}, \\mathbf{p}_{\\text{rb}}\\}} G(\\mathbf{p}_i, \\mathbf{q}) \\cdot \\mathbf{a}(\\mathbf{p}_i),\n",
        "$$\n",
        "\n",
        "where the bilinear interpolation weight $G(\\mathbf{p}, \\mathbf{q})$ is:\n",
        "\n",
        "$$\n",
        "G(\\mathbf{p}, \\mathbf{q}) = (1 - |{p}_x - {q}_{x}|) \\cdot (1 - |{p}_y - {q}_{y}|).\n",
        "$$\n",
        "\n",
        "With these definitions, we can write down deformable convolution in a complete form as follows:\n",
        "\n",
        "$$\n",
        "\\mathbf{a}^{l+1}(\\mathbf{p}_0) = \\sum_{k=0}^{K-1} \\mathbf{w}(k) \\cdot m_k \\cdot \\left( \\sum_{\\mathbf{p}_i} G(\\mathbf{p}_i, \\mathbf{p}_0 + \\mathbf{p}_k + \\Delta \\mathbf{p}_k) \\cdot \\mathbf{a}^l(\\mathbf{p}_i) \\right).\n",
        "$$\n",
        "\n",
        "For more details, please check the [paper](https://arxiv.org/abs/1811.11168) or [this tutorial](https://pub.towardsai.net/review-dcnv2-deformable-convnets-v2-object-detection-instance-segmentation-3d8a18bee2f5).\n",
        "\n",
        "You are expected to complete the given `deformable_conv2d_np()` function.\n",
        "\n",
        "**Do not change functions arguments and return value.**"
      ],
      "metadata": {
        "id": "yRAgl1rfpTEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bilinear_interpolate(a_l, q_y, q_x):\n",
        "    \"\"\"\n",
        "    Perform bilinear interpolation on the input activation map at the given (fractional) coordinates.\n",
        "\n",
        "    Args:\n",
        "        a_l (np.ndarray): 2D array of shape (H, W) representing the activation map (feature map) at a certain layer.\n",
        "        q_y (float): Y-coordinate (row index) where interpolation is to be performed.\n",
        "        q_x (float): X-coordinate (column index) where interpolation is to be performed.\n",
        "\n",
        "    Returns:\n",
        "        out (np.ndarray): Interpolated value at (q_x, q_y).\n",
        "    \"\"\"\n",
        "\n",
        "    pass\n",
        "\n",
        "    return out\n",
        "\n",
        "def deform_conv2d_np(a_l, delta, mask, weight, stride=1, padding=0, dilation=1):\n",
        "    \"\"\"\n",
        "    Deformable Conv2D v2 operation (forward pass) implemented in NumPy.\n",
        "\n",
        "    Args:\n",
        "        a_l (np.ndarray): Input feature map of shape (N, C_in, H_in, W_in),\n",
        "                            where N is the batch size, C_in is the number of\n",
        "                            input channels, and (H_in, W_in) are the height and\n",
        "                            width of the input feature map. input corresponds to\n",
        "                            'a^l' in the above formulation.\n",
        "\n",
        "        delta (np.ndarray): Learned/estimated offsets of shape (N, 2 * K_h * K_w, H_out, W_out),\n",
        "                             where K_h and K_w are the kernel height and width,\n",
        "                             and (H_out, W_out) are the spatial dimensions of\n",
        "                             the output feature map. The offset tensor corresponds\n",
        "                             to 'Delta-p' in the above formulation and provides\n",
        "                             the x and y displacements for each sampled point.\n",
        "\n",
        "        mask (np.ndarray): Learned modulation masks of shape (N, K_h*K_w, H_out, W_out).\n",
        "                           Corresponds to 'm' in the above formulation.\n",
        "\n",
        "        weight (np.ndarray): Convolution kernel of shape (C_out, C_in, K_h, K_w),\n",
        "                             where C_out is the number of output channels. Corresponds\n",
        "                             to 'w' in the above formulation.\n",
        "\n",
        "        stride (int): Stride of the convolution. Determines the spacing between\n",
        "                               sampled input locations. Default is 1.\n",
        "\n",
        "        padding (int): Zero-padding added to both sides of the input along height and width.\n",
        "                                Default is 0.\n",
        "\n",
        "        dilation (int): Dilation factor for the convolution kernel.\n",
        "                                 Controls the spacing between kernel elements. Default is 1.\n",
        "\n",
        "    Returns:\n",
        "        out (np.ndarray): Output feature map of shape (N, C_out, H_out, W_out),\n",
        "                          where each position is computed via deformable convolution using\n",
        "                          bilinearly interpolated input values and learned offsets.\n",
        "                          Corresponds to 'a^l+1' in the above formulation.\n",
        "    \"\"\"\n",
        "    #########################################################\n",
        "    # @TODO: Step 1: Preparing hyperparameters, pad input, and initialize output\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "\n",
        "    #########################################################\n",
        "    # @TODO: Step 2: Iterating over all coordinates\n",
        "    # HINT: You should constuct nested loops considering all dimensions of input and kernel\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "\n",
        "    #########################################################\n",
        "    # @TODO: Step 3: Calculating delta (offset) and mask\n",
        "    # HINT: Delta contains (dy, dx) for each kernel location; mask contains modulation strength.\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "    #########################################################\n",
        "    # @TODO: Step 4: Computing the deformed sampling position\n",
        "    # HINT: Compute the deformed sampling position\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "\n",
        "    #########################################################\n",
        "    # @TODO: Step 5: Bilinear interpolation from the input feature map\n",
        "    # HINT: Use bilinear interpolation to sample nearby pixel values.\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "    #########################################################\n",
        "    # @TODO: Step 6: Applying the convolution weight and modulation mask\n",
        "    # HINT: Multiply interpolated value by the learned weight and the modulation scalar.\n",
        "    #########################################################\n",
        "    pass\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "f1wDiLscVoO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Validate Implementations in Sections 1.1**\n",
        "\n",
        "Run the following cell to validate/check whether your implementations in Sections 1.1 are correct. You will see your grade calculated for this part.\n",
        "\n",
        "**Do not change/add any code here.**"
      ],
      "metadata": {
        "id": "STikCzQveAOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.ops import deform_conv2d\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# --- Define parameters ---\n",
        "N, C_in, H_in, W_in = 1, 3, 5, 5\n",
        "C_out, K_h, K_w = 2, 3, 3\n",
        "stride, padding, dilation = 1, 0, 1\n",
        "\n",
        "# Input\n",
        "np_input = np.arange(N * C_in * H_in * W_in, dtype=np.float32).reshape(N, C_in, H_in, W_in)\n",
        "torch_input = torch.tensor(np_input, dtype=torch.float32)\n",
        "\n",
        "# Offset: zero (no deformation)\n",
        "np_offset = np.random.rand(N, 2 * K_h * K_w, 3, 3).astype(np.float32)\n",
        "torch_offset = torch.tensor(np.copy(np_offset), dtype=torch.float32)\n",
        "\n",
        "# Mask: ones (no modulation)\n",
        "np_mask = np.ones((N, K_h * K_w, 3, 3), dtype=np.float32)\n",
        "torch_mask = torch.tensor(np_mask, dtype=torch.float32)\n",
        "\n",
        "# Weight: center=1\n",
        "np_weight = np.random.rand(C_out, C_in, K_h, K_w).astype(np.float32)\n",
        "torch_weight = torch.tensor(np.copy(np_weight), dtype=torch.float32)\n",
        "\n",
        "# Bias: zero\n",
        "np_bias = np.zeros((C_out), dtype=np.float32)\n",
        "torch_bias = torch.tensor(np.copy(np_bias), dtype=torch.float32)\n",
        "\n",
        "# --- Run NumPy Deformable Conv ---\n",
        "np_output = deform_conv2d_np(np_input, np_offset, np_mask, np_weight,\n",
        "                             stride=stride, padding=padding, dilation=dilation)\n",
        "\n",
        "# --- Run PyTorch Deformable Conv ---\n",
        "torch_output = deform_conv2d(\n",
        "    input=torch_input,\n",
        "    offset=torch_offset,\n",
        "    weight=torch_weight,\n",
        "    bias=torch_bias,\n",
        "    stride=stride,\n",
        "    padding=padding,\n",
        "    dilation=dilation,\n",
        "    mask=torch_mask\n",
        ")\n",
        "\n",
        "# --- Compare outputs ---\n",
        "print(\"NumPy Output:\\n\", np_output[0, 0])\n",
        "print(\"PyTorch Output:\\n\", torch_output[0, 0].detach().numpy())\n",
        "\n",
        "grade = 0\n",
        "if (np.allclose(np_output, torch_output.detach().numpy(), atol=1e-4) == True):\n",
        "    grade = 30\n",
        "else:\n",
        "    grade = 0\n",
        "print(\" Your grade is \", grade, \"/30.\")"
      ],
      "metadata": {
        "id": "1TV8vP-PeAlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2. Implement a CNN in PyTorch (40 pts)**\n",
        "\n",
        "In this task, you are expected to implement a training, validation and testing pipeline for a CNN model using PyTorch. You will work with CIFAR100 dataset which is available in torchvision.dataset.\n"
      ],
      "metadata": {
        "id": "y2i5j56MUIyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Implementing DataLoader (2.5 Points)**\n",
        "In this task, you should implement a dataloader for CIFAR100 dataset. It is  a built-in dataset in the torchvision.datasets module, i.e. **you do not need to implement custom dataloader**.  Here, you can find examples about how a built-in dataset can be used:\n",
        "\n",
        "*   https://pytorch.org/vision/main/datasets.html\n",
        "\n",
        "The official CIFAR100 dataset contains only training and test splits. Therefore, you are expected to create a validation split from training data randomly, with **80% used for training** and **the remaining 20% reserved for validation**.\n"
      ],
      "metadata": {
        "id": "i5zQ-QU3sNIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = None # set your batch size\n",
        "\n",
        "# Define transformations\n",
        "transform_train = transforms.Compose([\n",
        "\n",
        "   #####################################################\n",
        "    # @TODO: You can add your data augmentations here\n",
        "    # HINT: Do not forget to convert images to tensor\n",
        "    #####################################################\n",
        "])\n",
        "\n",
        "transform_validationAndtest = transforms.Compose([\n",
        "\n",
        "    #####################################################\n",
        "    # HINT: Do not forget to convert images to tensor\n",
        "    #####################################################\n",
        "])\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# @TODO:Define full training set\n",
        "#####################################################\n",
        "full_train_set = None # Modify this line\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Calculate split lengths , Perform split\n",
        "#####################################################\n",
        "train_size = None  # Modify this line\n",
        "val_size = None  # Modify this line\n",
        "\n",
        "train_set, val_set = None, None # @TODO: Modify this line\n",
        "\n",
        "# Update val_set transform to use validation transform\n",
        "val_set.dataset.transform = transform_validationAndtest\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Define Data loaders for training and validation splits\n",
        "#####################################################\n",
        "train_loader = None # Modify this line\n",
        "val_loader = None # Modify this line\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Define Test set and loader.\n",
        "#####################################################\n",
        "test_set = None # Modify this line\n",
        "test_loader = None #  Modify this line\n",
        "\n",
        "# ================================\n",
        "# Print Split Ratios\n",
        "# ================================\n",
        "print(f\"Total samples in CIFAR-100 training set: {len(full_train_set)}\")\n",
        "print(f\"Training split: {len(train_set)} samples ({len(train_set)/len(full_train_set)*100:.2f}%)\")\n",
        "print(f\"Validation split: {len(val_set)} samples ({len(val_set)/len(full_train_set)*100:.2f}%)\")\n",
        "print(f\"Test split: {len(test_set)} samples\")"
      ],
      "metadata": {
        "id": "d133Up5VsH_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Implement a CNN Model (2.5 Points)**\n",
        "In this task, you are expected to implement CustomCNN class according to the following specifications:\n",
        "\n",
        "*   Use at least three Conv2d Layers,\n",
        "*   Use at least one Pooling2d layer,\n",
        "*   Use at least two fully-connected layers,\n",
        "*   Do not use any normalization layer.\n",
        "\n",
        "There are no limitations for the model as long as you follow the above specifications."
      ],
      "metadata": {
        "id": "oGuKQ2z3w4TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, norm_layer= None):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Define layers of CNN. Do not forget to follow model specifications!.\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Implement the forward pass\n",
        "        # HINT: Apply activation functions like ReLU where necessary\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create model instance\n",
        "model = CustomCNN()\n",
        "\n",
        "# Print model summary\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "Nd3MdZ_TxMcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.3 Define Your Optimizer and Loss function**\n",
        "This task involves setting up a loss function and an optimizer for training a model. The loss function measures prediction accuracy. The optimizer, such as SGD or Adam, updates model weights based on the loss. Key parameters like learning rate and weight decay should be set appropriately. The model must also be moved to the correct device (CPU/GPU) before training.\n",
        "\n",
        "Here, you can reuse the relevant bit of your solution to THE1.\n"
      ],
      "metadata": {
        "id": "rdGKPcCkxl-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Define a loss function\n",
        "loss_function = None  # Replace with appropriate loss function for our classification task\n",
        "#####################################################\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Set your learning_rate, weight_decay or other optimizer-related parameters.\n",
        "pass\n",
        "#####################################################\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Replace with your model instance\n",
        "model = CustomCNN()\n",
        "#####################################################\n",
        "\n",
        "#####################################################\n",
        "# @TODO: pass model to device (CPU or GPU)\n",
        "pass\n",
        "#####################################################\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Choose an optimizer\n",
        "# HINT: Use optim.SGD or optim.Adam\n",
        "optimizer = None # Modify this line\n",
        "#####################################################\n",
        "\n",
        "# Print optimizer and loss function\n",
        "print(\"Loss Function:\", loss_function)\n",
        "print(\"Optimizer:\", optimizer)"
      ],
      "metadata": {
        "id": "l2DgGyJ7xskR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4 Optional Steps**\n",
        "You can use here for additional codes/implementations if necessary."
      ],
      "metadata": {
        "id": "IDD9sTc9yXTq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ic4hPUWjyUAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.5 Implement Training Pipeline (10 Points)**\n",
        "\n",
        "This task involves implementing training and validation loops for a model.\n",
        "\n",
        "* The `train()` function:\n",
        " * Iterates through the training data (`train_loader`).\n",
        " * For each batch, extracts images and labels, moves them to the appropriate device (CPU/GPU), performs a forward pass (calculates predictions and loss), and performs the backward pass (computes gradients and updates the model weights).\n",
        " * Returns the average training loss, top-1 and top-5 accuracies. (Top-1 accuracy measures how often the class with the highest prediction scores matches the ground truth, while Top-5 accuracy checks if the ground truth label is among the top 5 classes with the highest prediction scores.)\n",
        "\n",
        "* The `validate()` function:\n",
        " * Iterates through the validation data (`val_loader`) without updating the model weights (using `torch.no_grad()`).\n",
        " * Computes predictions, loss, and calculates accuracy by comparing predictions with true labels.\n",
        " * Returns the average validation loss and top-1 and top-5 accuracies.\n",
        "\n",
        "\n",
        "* These functions should be called in a loop for multiple epochs. Your final model should converge on the training data, so make sure to use an adequate number of epochs for proper training. You need to store and print the loss, top-1 and top-5 accuracies values for both training and validation after each epoch to track model performance."
      ],
      "metadata": {
        "id": "aTQ5PW8NyYXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, loss_function, device):\n",
        "    # get the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_top1 = 0.0\n",
        "    total_top5 = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: get images and their labels from the batch\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: pass your tensor to your device (CPU or GPU)\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Implement forward pass\n",
        "        # HINT: Compute predictions and loss\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "        total_loss += None # Modify this line\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Implement backward pass and optimization step\n",
        "        # HINT: Clear gradients, backpropagate, and update weights\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Update accuracy metrics and loss\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    avg_top1 = 100.0 * total_top1 / total_samples\n",
        "    avg_top5 = 100.0 * total_top5 / total_samples\n",
        "\n",
        "    return avg_loss, avg_top1, avg_top5\n",
        "\n",
        "def validate(model, val_loader, loss_function, device):\n",
        "    # get the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_top1 = 0.0\n",
        "    total_top5 = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            #####################################################\n",
        "            # @TODO: extract images and label from batch\n",
        "            pass\n",
        "            #####################################################\n",
        "\n",
        "            # TODO: pass your tensor to your device(CPU/GPU)\n",
        "            pass\n",
        "            #####################################################\n",
        "\n",
        "            # TODO: Implement validation forward pass\n",
        "            # HINT: Compute predictions and loss\n",
        "            pass\n",
        "            #####################################################\n",
        "\n",
        "            #####################################################\n",
        "            # TODO: Calculate accuracies\n",
        "            # HINT: Compare predictions with labels\n",
        "            pass\n",
        "            #####################################################\n",
        "\n",
        "    avg_loss = running_loss / total_samples\n",
        "    avg_top1 = 100.0 * total_top1 / total_samples\n",
        "    avg_top5 = 100.0 * total_top5 / total_samples\n",
        "\n",
        "    return avg_loss, avg_top1, avg_top5\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# @TODO: Call train and validate functions in a loop for multiple epochs\n",
        "# @TODO: Store loss value and accuracy of training and validation data for each epoch.\n",
        "#####################################################"
      ],
      "metadata": {
        "id": "45c_z_-BUCNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.6 Plot Loss Curves and Test Accuracies (5 Points)**\n",
        "In this task, you should plot two different graphs:\n",
        "\n",
        "1.   Training and validation losses versus epoch in a single graph.\n",
        "2.   Training and validation accuracies (both top-1 and top-5) versus epoch in a single graph.\n",
        "\n",
        "You should also report test accuracies (top-1 and top-5)."
      ],
      "metadata": {
        "id": "S-BO3sLL4jMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    # train_losses:    List to store training losses for each epoch\n",
        "    # val_losses:      List to store validation losses for each epoch\n",
        "\n",
        "    #####################################################\n",
        "    # @TODO: plot the training and validation loss\n",
        "    pass\n",
        "    #####################################################\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuries(train_top1, train_top5, val_top1, val_top5):\n",
        "    # train_top1: List to store training top-1 accuries for each epoch\n",
        "    # train_top5: List to store training top-5 accuries for each epoch\n",
        "    # val_top1:   List to store val top-1 accuries for each epoch\n",
        "    # val_top5:   List to store val top-5 accuries for each epoch\n",
        "\n",
        "    #####################################################\n",
        "    # @TODO: plot the training and validation accuries\n",
        "    pass\n",
        "    #####################################################\n",
        "    plt.show()\n",
        "\n",
        "def report_accuracy(test_loader, model):\n",
        "    correct_top1 = 0\n",
        "    correct_top5 = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch in test_loader:\n",
        "\n",
        "            #####################################################\n",
        "            # @TODO: get images and their labels from batch\n",
        "\n",
        "            # @TODO: pass your tensor to your device( CPU/GPU)\n",
        "\n",
        "            # @TODO: Implement validation forward pass\n",
        "            # HINT: Compute predictions and loss\n",
        "\n",
        "            # @TODO: Calculate accuracy\n",
        "            # HINT: Compare predictions with labels\n",
        "            pass\n",
        "            #####################################################\n",
        "\n",
        "    accuracy_top1 = (correct_top1 / total) * 100\n",
        "    accuracy_top5 = (correct_top5 / total) * 100\n",
        "    return accuracy_top1,accuracy_top5\n",
        "\n",
        "# call plot_loss and compute_confusion matrix function with appropriate parameters\n",
        "plot_loss(train_losses, val_losses) # @TODO: modify argument based on your code\n",
        "plot_accuries(train_accuracies_top1, train_accuracies_top5, val_accuracies_top1,val_accuracies_top5) #TODO: modify argument based on your code\n",
        "\n",
        "test_accuracy = report_accuracy(test_loader, model) # @TODO: modify argument based on your code\n",
        "print(f\"Test Accuracy top-1 and top-5: {test_accuracy[0]:.2f}% {test_accuracy[1]:.2f}%\")\n"
      ],
      "metadata": {
        "id": "O92UtpAB47r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.7 Change and Finetune Your Model (20 Points)**\n",
        "\n",
        "* Add BatchNorm2d with learnable parameters after each Conv2D layer.\n",
        "\n",
        "* Try different optimizers including SGD, Adam.\n",
        "\n",
        "* Search for a better **learning rate** on the validation data.\n",
        "\n",
        "* For each combination of model, optimizer and learning settings plot graphs mentioned in Section 2.7.\n",
        "\n",
        "* For the best parameters, model and optimizer settings, report test accuricies.\n",
        "\n",
        "* **Discuss your results** with respect to overfitting/underfitting and the impact of the hyper-parameters."
      ],
      "metadata": {
        "id": "R9rNpdLj53nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.7.1 Hyperparameter Optimization (5 Points)**\n",
        "In this part, you should perform hyperparameter optimization using all possible combinations (grid-search) of the given learning rates, optimizer and BatchNorm2d settings."
      ],
      "metadata": {
        "id": "WL5qFBKz4s48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you are expected re-implement your model in Section 2.2 using BatchNorm2D layer after each convlution layer."
      ],
      "metadata": {
        "id": "v1eBqzqNieJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNNwithBN(nn.Module):\n",
        "    def __init__(self, norm_layer= None):\n",
        "        super(CustomCNNwithBN, self).__init__()\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Define layers of CNN implemented in Section 2.3.\n",
        "        # You should use BatchNorm2D layer after each Conv2D layer.\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #####################################################\n",
        "        # @TODO: Implement the forward pass\n",
        "        # HINT: Apply activation functions like ReLU where necessary\n",
        "        pass\n",
        "        #####################################################\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create model instance\n",
        "model_bn = CustomCNNCustomCNNwithBN()\n",
        "\n",
        "# Print model summary\n",
        "print(model_bn)"
      ],
      "metadata": {
        "id": "0OSjL4Ne5l05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each combination, you should retrain your model from scratch and store the loss and accuracies of validation data. **All remaining settings/parameters should be fixed, except for the learning rate, optimizer and BatchNorm2d usage.**"
      ],
      "metadata": {
        "id": "da948hg9jSJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.0001, 0.001]\n",
        "optimizer_classes = [torch.optim.Adam, torch.optim.SGD]\n",
        "model_list = [model, model_bn]\n",
        "\n",
        "# @TODO: implement a nested for loop to make a grid search over the given\n",
        "# learning_rates, models and optimizers. Do not forget to reinitialize the model\n",
        "# to avoid weight sharing."
      ],
      "metadata": {
        "id": "vb-ZlSTc52y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.7.2 Choosing best parameters  (5 Points)**\n",
        "You should choose the parameters that give the highest top-1 accuracy on the validation data. Then, you should plot graph and report metrics mentioned in Section 2.7.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1UGEauun69fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @TODO: Find the best parameters that give the highest accuracy on the validation data.\n"
      ],
      "metadata": {
        "id": "41tLURQF7cqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.7.3 Discuss your results (10 Points)**\n",
        "In this section, you should discuss your results with respect to overfitting/underfitting and the impact of the hyper-parameters."
      ],
      "metadata": {
        "id": "yonO5mOu7gFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LdkrQCZrHx_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3: Implementing a RNN via torch.autograd (30 Points)**\n",
        "In this task, you should implement a Recurrent Neural Network (RNN) by manually unrolling an RNN and using PyTorch's `torch.autograd` to compute gradients explicitly.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eld-UX2dTr2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 Input Pre-processing**\n",
        "In this part, you are expected to process an input string to estimate a given target. We use the string \"Deep Learning\" for a character-level prediction task. For example:\n",
        "\n",
        "\n",
        "```\n",
        "input:  D e e p   L e a r n i n\n",
        "target: e e p   L e a r n i n g\n",
        "```\n",
        "\n",
        "Each character should be converted to a one-hot vector, and the model should predict the next character in the sequence.\n"
      ],
      "metadata": {
        "id": "o_CB3s54Gll0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#######################################################\n",
        "# 1. Define input text and build vocabulary\n",
        "#######################################################\n",
        "\n",
        "text = \"Deep Learning\"  # Input text for character-level modeling\n",
        "\n",
        "# Create a sorted list of unique characters.\n",
        "# 'chars' will contain all unique characters in the input text sorted in alphabetical order\n",
        "chars = None # @TODO: modify this line\n",
        "\n",
        "# Create a mapping from character to index (char2idx) and index to character (idx2char)\n",
        "# 'char2idx' will map each unique character to a unique index, and 'idx2char' will reverse that mapping\n",
        "char2idx = None # @TODO: modify this line\n",
        "idx2char = None # @TODO: modify this line\n",
        "\n",
        "#######################################################\n",
        "# 2. Create input and target sequences\n",
        "#######################################################\n",
        "\n",
        "# Input: all characters except the last one\n",
        "# This is the input sequence for the RNN model. The input sequence will be \"Deep Learnin\"\n",
        "input_seq = None  # @TODO: modify this line\n",
        "\n",
        "# Target: all characters except the first one\n",
        "# The target sequence is the same as the input sequence, but shifted by one character.\n",
        "# The target sequence will be \"eep Learning\"\n",
        "target_seq = None  # @TODO: modify this line\n",
        "\n",
        "#######################################################\n",
        "# 3. Define model hyperparameters\n",
        "#######################################################\n",
        "\n",
        "V = len(chars)       # Size of character vocabulary. Number of unique characters in the text.\n",
        "input_size = V       # One-hot input vector size. It's the same as vocab size, as each character is represented as one-hot.\n",
        "H = 16              # Number of hidden units in the RNN. This defines the dimensionality of the hidden state.\n",
        "output_size = V      # Output size. For each character in the sequence, we output a score for each possible character.\n",
        "seq_len = len(input_seq)      # Length of input sequence (i.e., the number of time steps).\n",
        "                              # This is the number of characters in the input sequence.\n",
        "\n",
        "\n",
        "# At this point, we have all the necessary components to train an RNN:\n",
        "# - A list of characters and their mappings to indices\n",
        "# - The input sequence and corresponding target sequence\n",
        "# - The hyperparameters that define the model's architecture\n",
        "\n",
        "#######################################################\n",
        "# 4. Convert characters to one-hot vectors\n",
        "#######################################################\n",
        "\n",
        "def one_hot(idx, size):\n",
        "    \"\"\"\n",
        "    Convert index to one-hot encoded vector of given size.\n",
        "\n",
        "    Args:\n",
        "    idx (int): The index of the character in the vocabulary.\n",
        "    size (int): The size of the one-hot encoded vector, typically equal to V.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: A one-hot encoded vector of size 'size' where the element at index 'idx' is 1, and all others are 0.\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    # @TODO: Implement one-hot decoding\n",
        "    #####################################################\n",
        "    vec = None\n",
        "    return vec\n",
        "\n",
        "# Convert entire input sequence to one-hot encoded tensors\n",
        "# The input sequence is a string, and each character needs to be converted to a one-hot vector using the 'one_hot' function.\n",
        "# For each character in the input sequence, its index is retrieved from 'char2idx', and then the corresponding one-hot vector is generated.\n",
        "\n",
        "inputs = None # @TODO: modify this line (Convert entire input sequence to one-hot encoded tensors)\n",
        "\n",
        "# Convert target characters to integer labels (indices)\n",
        "# The target sequence contains the next character for each input character, so each character needs to be mapped to an index.\n",
        "# This is a typical setup where the model outputs indices, which will later be converted to actual characters.\n",
        "\n",
        "targets = None # @TODO: modify this line (Convert target characters to integer labels (indices))"
      ],
      "metadata": {
        "id": "PH9y0-IKG803"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2 Implement a Training Pipeline (30 Points)**\n",
        "\n",
        "In this part, you should implement the following RNN for an autoregressive character prediction problem with the vocabulary size (the number of possible characters) of ${V}$, the hidden state size (the number of hidden units) of ${H}$, and given the input-output pair $(\\mathbf{x}=(\\mathbf{x}_1, \\mathbf{x}_2, ...), y)$ -- e.g., ($\\mathbf{x}=($'D', 'e', 'e'$), y=$'p'):\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{h}_t &= \\tanh(\\mathbf{W}_{xh} \\, \\mathbf{x}_t + \\mathbf{b}_{ih} + \\mathbf{W}_{hh} \\, \\mathbf{h}_{t-1} + \\mathbf{b}_{hh}), \\\\\n",
        "\\mathbf{s}_t &= \\mathbf{W}_{hy} \\, \\mathbf{h}_t + \\mathbf{b}_y, \\\\\n",
        "\\mathbf{\\hat{y}}_t &= \\text{softmax}(\\mathbf{s}_t),\n",
        "\\end{align*}  \n",
        "where\n",
        "\n",
        "*      $\\mathbf{x}_t$: one-hot encoded input at time step $t$ (size: $V$),\n",
        "*      $\\mathbf{h}_t$: hidden state at time step $t$ (size: $H$),\n",
        "*      $\\mathbf{s}_t$: output logits at time step $t$ (size: $V$),\n",
        "*      $\\mathbf{\\hat{y}}_t$: predicted probabilities (size: $V$),\n",
        "*      $\\mathbf{W}_{xh}$: input-to-hidden weight matrix (size: $H \\times V$),\n",
        "*      $\\mathbf{W}_{hh}$: hidden-to-hidden weight matrix (size: $H \\times H$),\n",
        "*      $\\mathbf{b}_{xh}$: hidden bias (size: $H$),\n",
        "*      $\\mathbf{b}_{hh}$: hidden bias (size: $H$),\n",
        "*      $\\mathbf{W}_{hy}$: hidden-to-output weight matrix (size: $V \\times H$),\n",
        "*      $\\mathbf{b}_y$: output bias (size: $V$).\n",
        "\n",
        "Then, you should calculate **negative log likelihood loss (NLL)** between predicted probabilities ${\\mathbf{\\hat{y}}}$ and target $\\mathbf{y}$:\n",
        "\n",
        "\n",
        "$${L}_{\\text{NLL}} = - \\sum_{i=1}^{N} \\sum_{c=1}^{V} \\mathbf{y}_{ic} \\log \\mathbf{\\hat{y}}_{ic}$$\n",
        "\n"
      ],
      "metadata": {
        "id": "1bpDc1tG1JjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################\n",
        "# @TODO: Define W_xh, W_hh, b_xh, b_hh, W_hy and b_y as differentiable tensors.\n",
        "#        Initialize all weights randomly using a standard normal distribution.\n",
        "# HINT: Use the given V and H in coding cell of \"Section 3.1 Input Pre-processing\" to define them.\n",
        "\n",
        "# Do not modify variables names!\n",
        "W_xh = None # @TODO: modify this line\n",
        "W_hh = None # @TODO: modify this line\n",
        "b_xh = None # @TODO: modify this line\n",
        "b_hh = None # @TODO: modify this line\n",
        "W_hy = None # @TODO: modify this line\n",
        "b_y = None  # @TODO: modify this line\n",
        "###########################################################################\n",
        "\n",
        "\n",
        "logits_list = []\n",
        "h = torch.zeros(H)\n",
        "# Go over each time step to update the hidden state first and then calculate\n",
        "# the logits\n",
        "for t in range(seq_len):\n",
        "    ###########################################################################\n",
        "    # @TODO: Fill in this part to calculate logits\n",
        "    pass\n",
        "    s_t = None # modify this line\n",
        "    ###########################################################################\n",
        "    logits_list.append(s_t)\n",
        "\n",
        "logits = torch.stack(logits_list)\n",
        "log_probs = F.log_softmax(logits, dim=1)\n",
        "loss_manual = F.nll_loss(log_probs, targets)"
      ],
      "metadata": {
        "id": "G_CnDSbQH5K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3 Compute the gradient explicitly via torch.autograd**\n",
        "In this part, you are expected compute gradient using torch.autograd explicitly for each parameter, i.e. gradients of loss value with respect to:\n",
        "\n",
        "*   $\\mathbf{W}_{xh}$\n",
        "*   $\\mathbf{W}_{hh}$\n",
        "*   $\\mathbf{b}_{xh}$\n",
        "*   $\\mathbf{b}_{hh}$\n",
        "*   $\\mathbf{W}_{hy}$\n",
        "*   $\\mathbf{b}_{y}$\n",
        "\n"
      ],
      "metadata": {
        "id": "8T_9KxRBJQFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate gradient for each parameter, separately.\n",
        "grad_W_xh =  None # @TODO: modify this line\n",
        "grad_W_hh =  None # @TODO: modify this line\n",
        "grad_b_xh =  None # @TODO: modify this line\n",
        "grad_b_hh =  None # @TODO: modify this line\n",
        "grad_W_hy =  None # @TODO: modify this line\n",
        "grad_b_y =   None # @TODO: modify this line\n",
        "\n",
        "\n",
        "# Now, concatenate the gradients\n",
        "manual_grads = [grad_W_xh, grad_W_hh, grad_b_xh, grad_b_hh, grad_W_hy, grad_b_y]"
      ],
      "metadata": {
        "id": "eGAqAPKfCyrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4 Validate Implementation in Section 3.3**\n",
        "This part is only to validate your implementation in Section 3.3 and see your grade.\n",
        "\n",
        "**Do not modify/add any code here!**"
      ],
      "metadata": {
        "id": "LSE-lud6KoR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn_cell = nn.RNNCell(input_size, H)\n",
        "        self.hidden_size = H\n",
        "        self.output_layer = nn.Linear(H, output_size)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.rnn_cell.weight_ih.copy_(W_xh)  # manual weight W_xh matches weight_ih\n",
        "            self.rnn_cell.weight_hh.copy_(W_hh)\n",
        "            self.rnn_cell.bias_ih.copy_(b_xh)\n",
        "            self.rnn_cell.bias_hh.copy_(b_hh)\n",
        "\n",
        "            self.output_layer.weight.copy_(W_hy)\n",
        "            self.output_layer.bias.copy_(b_y)\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        h = torch.zeros(self.hidden_size)\n",
        "        logits = []\n",
        "        for x in x_seq:\n",
        "            h = self.rnn_cell(x, h)\n",
        "            y = self.output_layer(h)\n",
        "            logits.append(y)\n",
        "        return torch.stack(logits)\n",
        "\n",
        "grade = 0\n",
        "model = SimpleRNN()\n",
        "\n",
        "logits_ref = model(inputs)\n",
        "log_probs_ref = F.log_softmax(logits_ref, dim=1)\n",
        "loss_ref = F.nll_loss(log_probs_ref, targets)\n",
        "loss_ref.backward()\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Compare Gradients\n",
        "# ----------------------------\n",
        "\n",
        "param_names = ['W_xh', 'W_hh', 'b_xh', 'b_hh', 'W_hy', 'b_y']\n",
        "model_grads = []\n",
        "\n",
        "#get model gradient\n",
        "for name, param in model.named_parameters():\n",
        "    if param.grad is not None:\n",
        "        model_grads.append(param.grad)\n",
        "\n",
        "for name, g1, g2 in zip(param_names, manual_grads, model_grads):\n",
        "    diff = (g1 - g2).abs().max()\n",
        "    print(f\"Δ {name}: max abs diff = {diff:.6e}\")\n",
        "    if diff > 1e-4:\n",
        "        print(\"❗ Significant difference\")\n",
        "    else:\n",
        "        grade += 5\n",
        "print(f\" Your grade is {grade}/30\")"
      ],
      "metadata": {
        "id": "FPH_wMH7K9XC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}